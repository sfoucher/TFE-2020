{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO78fJZyxe91+xfq+EdIX5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexandre-Delplanque/TFE-2020/blob/master/Model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1elMli_l30W-",
        "colab_type": "text"
      },
      "source": [
        "# OBJECT DETECTION - MODEL 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SsQcNfM37VW",
        "colab_type": "text"
      },
      "source": [
        "## Importation des librairies et liaison à Mon Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGTLZxn1a5b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################################################################\n",
        "#                         OBJECT DETECTION MODEL 1                          #\n",
        "#############################################################################\n",
        "\n",
        "'''\n",
        "Premier essai de modèle de détection d'objets, basé sur le tutoriel Pytorch :\n",
        "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# --- Importation des librairies ---\n",
        "\n",
        "# OS\n",
        "import os\n",
        "# PyTorch\n",
        "import torch\n",
        "import torchvision\n",
        "# NumPy\n",
        "import numpy as np\n",
        "# Pillow\n",
        "from PIL import Image\n",
        "# Json\n",
        "import json\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# OpenCV\n",
        "import cv2\n",
        "# Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT3G-H7I4Ceo",
        "colab_type": "text"
      },
      "source": [
        "## Modification de \"cocoeval.py\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9ciD8mNiQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Modification du fichier 'cocoeval.py' afin de pouvoir utiliser la librairie ---\n",
        "\n",
        "import re \n",
        "\n",
        "# Chemin d'accès vers le fichier cocoeval.py\n",
        "fname = \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\"\n",
        "\n",
        "with open(fname) as f:\n",
        "    # Lecture du fichier\n",
        "    s = f.read()\n",
        "    # Remplacement des lignes de code\n",
        "    s = re.sub('self.iouThrs = (.+)',\n",
        "               'self.iouThrs = np.linspace(.5, 0.95, (np.round((0.95 - .5) / .05) + 1).astype(np.int), endpoint=True)', s)\n",
        "    s = re.sub('self.recThrs = (.+)',\n",
        "               'self.recThrs = np.linspace(.0, 1.00, (np.round((1.00 - .0) / .01) + 1).astype(np.int), endpoint=True)', s)\n",
        "\n",
        "# Ecriture dans le fichier\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSoTRPyf4JXw",
        "colab_type": "text"
      },
      "source": [
        "## Importation des fonctions personnelles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBAXNit5-JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bounding_box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ayO35iZcW1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python \"/content/drive/My Drive/Obj_Detection_M1/alex_utils.py\"\n",
        "!python \"/content/drive/My Drive/Obj_Detection_M1/engine.py\"\n",
        "!python \"/content/drive/My Drive/Obj_Detection_M1/utils.py\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MLyWagKcevX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perso\n",
        "%cd '/content/drive/My Drive/Obj_Detection_M1/'\n",
        "from alex_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKXo2V9T4On-",
        "colab_type": "text"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuNHoMK2bjyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Définition du dossier de travail ---\n",
        "\n",
        "work_dir = \"/content/drive/My Drive/Obj_Detection_M1/\"\n",
        "\n",
        "print(work_dir)\n",
        "\n",
        "# Classes\n",
        "animals_names = [\"Bubale\",\"Buffalo\",\"Hippopotamus\",\"Kob\",\"Topi\",\"Warthog\",\"Waterbuck\"]\n",
        "animals_labels = [1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "# --- Sélection du processeur de calcul ---\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "if not use_cuda:\n",
        "  print(\"WARNING: PYTORCH COULD NOT LOCATE ANY AVAILABLE CUDA DEVICE\")\n",
        "else:\n",
        "  print(\"All good, a GPU is available.\")\n",
        "\n",
        "# --- Infos sur le GPU disponible ---\n",
        "t = torch.cuda.get_device_properties(0).total_memory\n",
        "t_GB = t/float((1024**3))\n",
        "c = torch.cuda.memory_cached(0)\n",
        "c_GB = c/float((1024**3))\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "a_GB = a/float((1024**3))\n",
        "f = c-a\n",
        "f_GB = f/float((1024**3))\n",
        "\n",
        "print(\"{:<30}{:<25}\".format(\"Mémoire totale (GB) :\",t_GB))\n",
        "print(\"{:<30}{:<25}\".format(\"Mémoire cachée (GB) :\",c_GB))\n",
        "print(\"{:<30}{:<25}\".format(\"Mémoire allouée (GB) :\",a_GB))\n",
        "print(\"{:<30}{:<25}\".format(\"Mémoire disponible (GB) :\",f_GB))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBwdSljAeayQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Téléchargment des données (GitHub) ---\n",
        "\n",
        "%cd '/content/'\n",
        "\n",
        "# Clone du repo contenant la data\n",
        "git_repo_data = 'https://github.com/Alexandre-Delplanque/ObjectDetection_Model_2_MMdet.git' \n",
        "!git clone $git_repo_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ptPbc0hC3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/\n",
        "\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "%cd /content\n",
        "data_dir = os.path.abspath(splitext(basename(git_repo_data))[0])\n",
        "print(\"Data path : {}\".format(data_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ggE4yOJh1Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Téléchargement des annotations (fichiers .json) ---\n",
        "\n",
        "ann_path = data_dir + \"/annotations\"\n",
        "\n",
        "with open(os.path.join(ann_path,'train_cocotype.json')) as json_file:\n",
        "    train_js = json.load(json_file)\n",
        "\n",
        "with open(os.path.join(ann_path,'val_cocotype.json')) as json_file:\n",
        "    val_js = json.load(json_file)\n",
        "\n",
        "with open(os.path.join(ann_path,'test_cocotype.json')) as json_file:\n",
        "    test_js = json.load(json_file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ClkpQuI4YXT",
        "colab_type": "text"
      },
      "source": [
        "## Analyse des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyFqa4qqjLJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Analyse du dataset ---\n",
        "\n",
        "# Calcul du nombre d'animaux par set de données\n",
        "\n",
        "# Train\n",
        "dist_train = []\n",
        "dist_class_train = []\n",
        "for i in range(len(train_js['annotations'])):\n",
        "    dist_class_train.append(train_js['annotations'][i]['category_id'])\n",
        "\n",
        "# Validation\n",
        "val_test = []\n",
        "dist_class_val = []\n",
        "for i in range(len(val_js['annotations'])):\n",
        "    dist_class_val.append(val_js['annotations'][i]['category_id'])\n",
        "\n",
        "# Test\n",
        "dist_test = []\n",
        "dist_class_test = []\n",
        "for i in range(len(test_js['annotations'])):\n",
        "    dist_class_test.append(test_js['annotations'][i]['category_id'])\n",
        "\n",
        "# Print des infos du dataset\n",
        "print('{:<15}{:<10}{:<10}'.format(\"DATASET\",\"IMAGES\",\"ANIMALS\"))\n",
        "print('-'*35)\n",
        "print('{:<15}{:<10}{:<10}'.format(\"Train\",len(train_js['images']),len(train_js['annotations'])))\n",
        "print('{:<15}{:<10}{:<10}'.format(\"Validation\",len(val_js['images']),len(val_js['annotations'])))\n",
        "print('{:<15}{:<10}{:<10}'.format(\"Test\",len(test_js['images']),len(test_js['annotations'])))\n",
        "print('-'*35)\n",
        "\n",
        "# Distribution des classes\n",
        "\n",
        "import collections\n",
        "\n",
        "# Calcul des distributions de fréquences\n",
        "cl_train_counter = dict(collections.Counter(dist_class_train))\n",
        "cl_test_counter = dict(collections.Counter(dist_class_test))\n",
        "\n",
        "# Mise en graphique\n",
        "plt.figure(1,figsize=(10,10))\n",
        "bins = [x + 0.5 for x in range(0, len(cl_train_counter)+1)]\n",
        "fig = plt.hist([dist_class_train, dist_class_val, dist_class_test], bins=bins, edgecolor='dimgray', color=['skyblue','khaki','ivory'])\n",
        "axes = plt.gca()\n",
        "axes.set_xlabel('Animal')\n",
        "axes.xaxis.set_ticklabels([0]+animals_names)\n",
        "axes.set_ylabel('Effectif')\n",
        "plt.legend(['Entrainement','Validation','Test'], frameon=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc2r_uN54c7z",
        "colab_type": "text"
      },
      "source": [
        "## Pondération des classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RM0pMAKnQnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Pondération des classes ---\n",
        "\n",
        "# Vecteur de pondérations\n",
        "'''\n",
        "Pondération selon l'inverse de la fréquence de la classe dans le jeu\n",
        "de données d'entrainement.\n",
        "\n",
        "Résultats satisfaisants pour Kellenberger et al. (2018).\n",
        "\n",
        "Attention le vecteur doit être un Tensor!\n",
        "'''\n",
        "\n",
        "n_train = []\n",
        "for i in sorted(cl_train_counter.keys()):\n",
        "    n_train.append(cl_train_counter[i])\n",
        "\n",
        "n_train = torch.FloatTensor(n_train)\n",
        "class_weights = torch.min(n_train)/n_train\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights = class_weights.to(device) # Calcul via GPU\n",
        "\n",
        "print(class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQ5fFGhriJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E144OHR4iS2",
        "colab_type": "text"
      },
      "source": [
        "## Installation d'albumentations (Data Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIpxYhqzW64Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installation de la librairie \"albumentations\" (data augmentation)\n",
        "!pip install -U git+https://github.com/albu/albumentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCiCOwMw4voy",
        "colab_type": "text"
      },
      "source": [
        "## Préparation du dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KVnz5cZ4z0_",
        "colab_type": "text"
      },
      "source": [
        "### Création : \"MammalsDataset()\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUzORn3P0VO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Création d'un dataset ---\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MammalsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root, transforms=None, train=True, test=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "\n",
        "        if train == True:\n",
        "\n",
        "            with open(os.path.join(root,'annotations/train_cocotype.json')) as json_file:\n",
        "                self.data = json.load(json_file)\n",
        "            \n",
        "            self.root_images = os.path.join(root,'train')\n",
        "\n",
        "        elif train == False:\n",
        "\n",
        "            with open(os.path.join(root,'annotations/val_cocotype.json')) as json_file:\n",
        "                self.data = json.load(json_file)\n",
        "            \n",
        "            self.root_images = os.path.join(root,'val')\n",
        "        \n",
        "        if test == True:\n",
        "\n",
        "            with open(os.path.join(root,'annotations/test_cocotype.json')) as json_file:\n",
        "                self.data = json.load(json_file)\n",
        "\n",
        "            self.root_images = os.path.join(root,'test')\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image_name = self.data['images'][idx]['file_name']\n",
        "        image_id = self.data['images'][idx]['id']\n",
        "\n",
        "        img_path = os.path.join(self.root_images,image_name)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Initialisation du dictionnaire\n",
        "        target = {}\n",
        "\n",
        "        boxes = []\n",
        "        area = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in range(len(self.data['annotations'])):\n",
        "          if self.data['annotations'][ann]['image_id']== image_id:\n",
        "            xmin = self.data['annotations'][ann]['bbox'][0]\n",
        "            ymin = self.data['annotations'][ann]['bbox'][1]\n",
        "            new_box = [xmin,\n",
        "                       ymin,\n",
        "                       xmin + self.data['annotations'][ann]['bbox'][2],\n",
        "                       ymin + self.data['annotations'][ann]['bbox'][3]]\n",
        "            boxes.append(new_box)\n",
        "            labels.append(self.data['annotations'][ann]['category_id'])\n",
        "            area.append(self.data['annotations'][ann]['area'])\n",
        "\n",
        "        # Area\n",
        "        area = torch.as_tensor(area, dtype=torch.float32)\n",
        "\n",
        "        # Image ID\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        # IsCrowd : on suppose = 0 pour tous\n",
        "        nbr_obj = len(labels)\n",
        "        iscrowd = torch.zeros(nbr_obj, dtype=torch.int64) \n",
        "\n",
        "        # Transformations\n",
        "        if self.transforms is not None:\n",
        "\n",
        "            # Image\n",
        "            image_np = np.array(img)\n",
        "            augmented  = self.transforms(image = image_np, bboxes = boxes)\n",
        "            img = Image.fromarray(augmented['image'])\n",
        "\n",
        "            # BBoxes\n",
        "            boxes = augmented['bboxes']\n",
        "\n",
        "        # Image en tensor\n",
        "        img_to_tensor = torchvision.transforms.ToTensor()\n",
        "        img = img_to_tensor(img)\n",
        "\n",
        "        # Label en tensor\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        # Bounding Box en tensor\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "        # Remplissage du dictionnaire\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd  \n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['images'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueHGo1Y-45oN",
        "colab_type": "text"
      },
      "source": [
        "### Transformations (Data augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJBcFPZPrSkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Transformations ---\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# Prétraitements\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Albumentations (data augmentation)\n",
        "from albumentations import Compose, HorizontalFlip, VerticalFlip, BboxParams\n",
        "from albumentations import Blur, RandomBrightness, RandomRotate90\n",
        "\n",
        "# Initialisation de 'labels' pour éviter l'erreur de variable non-déclarée\n",
        "# Remplacée par la list de labels dans le dataset lors du chrgt du dataloader\n",
        "labels = [] \n",
        "\n",
        "data_transforms = {\n",
        "    'train': Compose([        \n",
        "        VerticalFlip(p=0.5),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        RandomRotate90(p=0.5),\n",
        "        RandomBrightness(limit=(-0.2,-0.2),p=0.5),\n",
        "        RandomBrightness(limit=(0.2,0.2),p=0.5),\n",
        "        Blur(blur_limit=(25, 25), p=0.5)\n",
        "        ],\n",
        "\n",
        "        # Obligatoire pour spécifier le format des BBox (x1,y1,x2,y2)\n",
        "        # et le label_fields pour associer chaque bbox à un label\n",
        "        bbox_params=BboxParams(format='pascal_voc', label_fields=labels)\n",
        "    ),\n",
        "\n",
        "    'val': Compose([\n",
        "    ]),\n",
        "\n",
        "    'test': Compose([\n",
        "    ]),\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TffnAjYE5Azd",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylmIo1LJnc9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Dataset et Dataloader ---\n",
        "\n",
        "# Dataset\n",
        "# -------------\n",
        "train_dataset = MammalsDataset(root=data_dir, transforms=data_transforms['train'], train=True)\n",
        "val_dataset = MammalsDataset(root=data_dir, transforms=data_transforms['val'], train=False)\n",
        "test_dataset = MammalsDataset(root=data_dir, transforms=data_transforms['test'], train=False, test=True)\n",
        "\n",
        "image_datasets = {'train': train_dataset,'val': val_dataset,'test': test_dataset}\n",
        "\n",
        "# Dataloader\n",
        "# -------------\n",
        "# Besoin d'une fonction collate_fn() pour créer les batchs\n",
        "# car les images ne contiennent pas le même nombre d'objets\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# Taille d'un batch\n",
        "batch_size = 2\n",
        "\n",
        "# Dataloader\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=0,\n",
        "                                              collate_fn=collate_fn)\n",
        "              for x in ['train', 'val', 'test']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "\n",
        "# Classes\n",
        "# -------------\n",
        "class_names = ['Background'] + animals_names\n",
        "num_class = len(class_names)\n",
        "\n",
        "\n",
        "# Visualisation des classes et des tailles de datasets\n",
        "print(\"Nombre de classes : \",num_class)\n",
        "print(\"Noms des classes : \",class_names)\n",
        "print(\"Espèces animales : \",animals_names)\n",
        "print(\"Tailles des datasets : \",dataset_sizes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDcutXHi5DqV",
        "colab_type": "text"
      },
      "source": [
        "## Visualisation d'un batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wqJaZhd5L9F",
        "colab_type": "text"
      },
      "source": [
        "### Fonction de visualisation : \"BatchPlot()\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NczTxr2ptqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Fonction de plot d'un batch, ou d'une prédiction ---\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def BatchPlot(images, targets, dataset_dic, labels_dic, save=False, predictions=None, img_names=False, legend=False):\n",
        "    # Images et targets sur CPU\n",
        "    images = list(image.to('cpu') for image in images)\n",
        "    targets = [{k: v.to('cpu') for k, v in t.items()} for t in targets]\n",
        "\n",
        "    # Transformation de l'image en PIL\n",
        "    tensor_to_PIL = torchvision.transforms.ToPILImage(mode='RGB')\n",
        "\n",
        "    # Couleurs des classes\n",
        "    labels_color = ['b','r','c','m','orange','lime','aquamarine','peru','silver']\n",
        "\n",
        "    # Noms des classes\n",
        "    cls_names = []\n",
        "    color_names = []\n",
        "\n",
        "    if len(images)>1:\n",
        "        # Création de fig et ax\n",
        "        fig, ax = plt.subplots(1,len(images), figsize = (30, 20))\n",
        "\n",
        "        # Plot des images et leurs bounding boxes\n",
        "        for i in range(len(images)):\n",
        "\n",
        "            cls_names = []\n",
        "            color_names = []\n",
        "\n",
        "            # Titre = nom de l'image\n",
        "            if img_names == True:\n",
        "                # ID de l'image\n",
        "                ID = targets[i]['image_id']\n",
        "                # Nom\n",
        "                img_name = dataset_dic['images'][ID]['file_name']\n",
        "                img_width = images[i].size()[2]\n",
        "                img_height = images[i].size()[1]\n",
        "                title = 'Image : {}\\nObjet(s) : {}'.format(img_name,len(targets[i]['boxes']))\n",
        "                ax[i].text(int(img_width/200), int(img_height/30), title, size='x-large', bbox=dict(boxstyle='round',facecolor='w', alpha=0.6))\n",
        "\n",
        "            # Plot\n",
        "            ax[i].axis('off')\n",
        "            image = tensor_to_PIL(images[i])\n",
        "            ax[i].imshow(image)\n",
        "\n",
        "            for box in range(len(targets[i]['boxes'])):\n",
        "\n",
        "                # Couleur bboxe et nom pour légende\n",
        "                label = int(targets[i]['labels'][box])\n",
        "                color = labels_color[label-1]\n",
        "                color_names.append(color)\n",
        "                name = labels_dic[label]\n",
        "                cls_names.append(name)\n",
        "            \n",
        "                bboxe = targets[i]['boxes'][box]\n",
        "                rect = patches.Rectangle((bboxe[0],bboxe[1]), bboxe[2]-bboxe[0], bboxe[3]-bboxe[1],linewidth=0.5,edgecolor=color,facecolor='none')\n",
        "                ax[i].add_patch(rect)\n",
        "            \n",
        "            # Légende = boxes et couleur\n",
        "            if legend == True:\n",
        "                rects = []\n",
        "                cls_names = [x for j, x in enumerate(cls_names) if cls_names.index(x) == j]\n",
        "                color_names = [x for j, x in enumerate(color_names) if color_names.index(x) == j]\n",
        "                for o in range(len(cls_names)):\n",
        "                    rect = patches.Rectangle((0,0), 100, 100,linewidth=1,edgecolor=color_names[o],facecolor='none')\n",
        "                    rects.append(rect)\n",
        "\n",
        "                ax[i].legend(rects,cls_names)\n",
        "\n",
        "            if predictions is not None:\n",
        "\n",
        "                for box in range(len(predictions[i]['boxes'])):\n",
        "                    bboxe = predictions[i]['boxes'][box]\n",
        "                    rect = patches.Rectangle((bboxe[0],bboxe[1]), bboxe[2]-bboxe[0], bboxe[3]-bboxe[1],linewidth=0.5,edgecolor='r',facecolor='none')\n",
        "                    ax[i].add_patch(rect)\n",
        "\n",
        "    else:\n",
        "        fig, ax = plt.subplots(1, figsize = (30, 20))\n",
        "        ax.axis('off')\n",
        "        image = tensor_to_PIL(images[0])\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Titre = nom de l'image\n",
        "        if img_names == True:\n",
        "            # ID de l'image\n",
        "            ID = targets[0]['image_id']\n",
        "            # Nom\n",
        "            img_name = dataset_dic['images'][ID]['file_name']\n",
        "            img_width = images[0].size()[2]\n",
        "            img_height = images[0].size()[1]\n",
        "            title = 'Image : {}\\nObjet(s) : {}'.format(img_name,len(targets[0]['boxes']))\n",
        "            ax.text(int(img_width/200), int(img_height/30), title, size='x-large', bbox=dict(boxstyle='round', facecolor='w', alpha=0.6))\n",
        "\n",
        "        for box in range(len(targets[0]['boxes'])):\n",
        "\n",
        "            # Couleur bboxe et nom pour légende\n",
        "            label = int(targets[0]['labels'][box])\n",
        "            color = labels_color[label-1]\n",
        "            color_names.append(color)\n",
        "            name = labels_dic[label]\n",
        "            cls_names.append(name)\n",
        "            \n",
        "            bboxe = targets[0]['boxes'][box]\n",
        "            rect = patches.Rectangle((bboxe[0],bboxe[1]), bboxe[2]-bboxe[0], bboxe[3]-bboxe[1],linewidth=1,linestyle='--',edgecolor=color,facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "        \n",
        "        # Légende = boxes et couleur\n",
        "        if legend == True:\n",
        "            rects = []\n",
        "            cls_names = [x for i, x in enumerate(cls_names) if cls_names.index(x) == i]\n",
        "            color_names = [x for i, x in enumerate(color_names) if color_names.index(x) == i]\n",
        "            for o in range(len(cls_names)):\n",
        "                rect = patches.Rectangle((0,0), 100, 100,linewidth=1,edgecolor=color_names[o],facecolor='none')\n",
        "                rects.append(rect)\n",
        "\n",
        "            ax.legend(rects,cls_names)\n",
        "\n",
        "        if predictions is not None:\n",
        "\n",
        "            for box in range(len(predictions[0]['boxes'])):\n",
        "\n",
        "                label = int(predictions[0]['labels'][box])\n",
        "                color = labels_color[label-1]\n",
        "\n",
        "                bboxe = predictions[0]['boxes'][box]\n",
        "                rect = patches.Rectangle((bboxe[0],bboxe[1]), bboxe[2]-bboxe[0], bboxe[3]-bboxe[1],linewidth=1,edgecolor=color,facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "        if save == True:\n",
        "            plt.savefig(os.path.join(\"/content/drive/My Drive/Obj_Detection_M1/Annotations/train\",img_name)) \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL0OLOq-ItWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation d'un batch\n",
        "%matplotlib inline\n",
        "labels_dic = {\n",
        "    1: 'Bubale',\n",
        "    2: 'Buffle',\n",
        "    3: 'Hippo',\n",
        "    4: 'Cob',\n",
        "    5: 'Topi',\n",
        "    6: 'Phacochere',\n",
        "    7: 'Cob a croissant'\n",
        "}\n",
        "\n",
        "images, targets = next(iter(dataloaders['train']))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "\n",
        "BatchPlot(images, targets, train_js, labels_dic,save=False, img_names=True, legend=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I245dnPXNODl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "labels_dic = {\n",
        "    1: 'Bubale',\n",
        "    2: 'Buffle',\n",
        "    3: 'Hippo',\n",
        "    4: 'Cob',\n",
        "    5: 'Topi',\n",
        "    6: 'Phacochere',\n",
        "    7: 'Cob a croissant'\n",
        "}\n",
        "\n",
        "# Dataloader spécifique à une image\n",
        "img_name = \"S_07_05_16_DSC00570.JPG\"\n",
        "dic = test_js\n",
        "\n",
        "def SpecificImgDisplay(img_name, dataset, dic, predictions=False):\n",
        "    for row in range(len(dic['images'])):\n",
        "        if dic['images'][row]['file_name']==img_name:\n",
        "            ID_img = int(row)\n",
        "\n",
        "    specific_dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                                  batch_size=1,\n",
        "                                                  shuffle=False,\n",
        "                                                  collate_fn=collate_fn,\n",
        "                                                  sampler=torch.utils.data.SubsetRandomSampler([ID_img]),\n",
        "                                                  num_workers=0)\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "\n",
        "    # Obtention d'un batch\n",
        "    images_b, targets_b = next(iter(specific_dataloaders[dataset]))\n",
        "    images = list(image for image in images_b)\n",
        "    targets = [{k: v for k, v in t.items()} for t in targets_b]\n",
        "\n",
        "    # Plot\n",
        "    if predictions is False:\n",
        "        BatchPlot(images, targets, dic, labels_dic,save=False, img_names=True, legend=True)\n",
        "    elif predictions is True:\n",
        "        model.eval()\n",
        "        images = list(image.to(device) for image in images_b)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets_b]\n",
        "        out = model(images)\n",
        "\n",
        "        # Non-Maximum Supression (NMS)\n",
        "        nms_treshold = 0.35\n",
        "        out_nms = [NMScustom(boxes=out[0]['boxes'], \n",
        "                            labels=out[0]['labels'], \n",
        "                            scores=out[0]['scores'], \n",
        "                            tresh=nms_treshold)]\n",
        "\n",
        "        # Seuillage sur les scores\n",
        "        cutoff_treshold = 0.20\n",
        "        out_nms_cut = [CutOffScores(boxes=out_nms[0]['boxes'], \n",
        "                                    labels=out_nms[0]['labels'], \n",
        "                                    scores=out_nms[0]['scores'], \n",
        "                                    tresh=cutoff_treshold)]\n",
        "\n",
        "        BatchPlot(images, targets, dic, predictions=out_nms_cut, labels_dic=labels_dic, save=False, img_names=True, legend=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlEHaqt32FLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_name = input('Nom de l\\'image (train) : ')\n",
        "SpecificImgDisplay(img_name, dataset='train', dic=train_js, predictions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjGt4cr9COug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_name = \"L_07_05_16_DSC00441.JPG\"\n",
        "SpecificImgDisplay(img_name, dataset='train', dic=train_js, predictions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY2lUBsd5TWA",
        "colab_type": "text"
      },
      "source": [
        "### Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj-7TOdBxWGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Visualisation d'un batch et ses bboxes ---\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "labels_dic = {\n",
        "    1: 'Bubale',\n",
        "    2: 'Buffle',\n",
        "    3: 'Hippo',\n",
        "    4: 'Cob',\n",
        "    5: 'Topi',\n",
        "    6: 'Phacochere',\n",
        "    7: 'Cob a croissant'\n",
        "}\n",
        "\n",
        "# Obtention d'un batch  de données d'entrainement\n",
        "for i, (images, targets) in enumerate(order_dataloaders['train']):\n",
        "\n",
        "    # images = list(image for image in images)\n",
        "    # targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "\n",
        "    # Plot\n",
        "    print('Image [{}/{}]'.format(i+1,len(image_datasets['train'])))\n",
        "\n",
        "    BatchPlot(images, targets, train_js, labels_dic, save=False, img_names=True, legend=True)\n",
        "\n",
        "    # Passage à l'image suivante\n",
        "    print(\"Appuyer sur ENTER pour passer à l'image suivante...\")\n",
        "    input()\n",
        "\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAUdrSMu5YBZ",
        "colab_type": "text"
      },
      "source": [
        "## Chargement du modèle et transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wif5v47pxITG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Chargement du modèle ---\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# Chargement d'un modèle pré-entrainé (COCO)\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# --- Ajustement du classifier ---\n",
        "\n",
        "# Nombre d'inputs du classifier\n",
        "num_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "# Remplacement du classifier\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(num_features, num_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3RHi6M_CD8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Entrainement du modèle ---\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Instanciation de la fonction de coût sous forme d'un objet\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#optimizer_ft = optim.SGD(model.parameters(), lr=0.01, momentum=0.9,weight_decay=0.0005)\n",
        "\n",
        "optimizer_ft = optim.SGD([\n",
        "                          {'params':model.backbone.parameters(), 'lr':0.001},\n",
        "                          {'params':model.roi_heads.box_predictor.parameters(), 'lr':0.005}\n",
        "                         ], lr=0.005, momentum=0.9,weight_decay=0.0005)\n",
        "\n",
        "\n",
        "\n",
        "# Diminution du LR de l toutes les k epochs\n",
        "l = 0.1\n",
        "k = 7\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=k, gamma=l)\n",
        "\n",
        "# Modèle poussé sur le GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCPPsYdr5c_y",
        "colab_type": "text"
      },
      "source": [
        "## Entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N75zvX-tCMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "%cd '/content/drive/My Drive/Obj_Detection_M1/'\n",
        "import utils\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Entrainement sur une epoch et print tous les 50 itérations\n",
        "    train_one_epoch(model, optimizer_ft, dataloaders['train'], device, epoch, print_freq=50)\n",
        "    # Mis à jour du learning rate\n",
        "    exp_lr_scheduler.step()\n",
        "    # Evaluation sur le dataset de test\n",
        "    evaluate(model, dataloaders['val'], device=device)\n",
        "    # Vider le cache du GPU\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "checkpoint_file = work_dir + \"Checkpoints/NEW_M1_OD_30_DA_2_ALL.pth\"\n",
        "torch.save(model.state_dict(), checkpoint_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHlYSb1b5ken",
        "colab_type": "text"
      },
      "source": [
        "## Chargement des paramètres d'un modèle entrainé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYigy1gtjeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Chargement des paramètres du modèle ---\n",
        "\n",
        "checkpoint_file = work_dir + \"Checkpoints/NEW_M1_OD_30_DA_2_ALL.pth\"\n",
        "\n",
        "# Sauver\n",
        "#torch.save(model.state_dict(), checkpoint_file)\n",
        "\n",
        "# Loader\n",
        "model.load_state_dict(torch.load(checkpoint_file))\n",
        "\n",
        "# Téléchargement\n",
        "# from google.colab import files\n",
        "# files.download(checkpoint_file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5KmuW4X5ol6",
        "colab_type": "text"
      },
      "source": [
        "## Prédictions d'un batch aléatoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsyB_x1M5weP",
        "colab_type": "text"
      },
      "source": [
        "### Prédictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoxgbLHS1KXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Prédictions d'un batch aléatoire ---\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Dataloader\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                              batch_size=1,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=0,\n",
        "                                              collate_fn=collate_fn)\n",
        "              for x in ['train', 'val', 'test']}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "imgs_test, targs_test = next(iter(dataloaders['test']))\n",
        "imgs_test = list(image.to(device) for image in imgs_test)\n",
        "targs_test = [{k: v.to(device) for k, v in t.items()} for t in targs_test]\n",
        "\n",
        "out = model(imgs_test)\n",
        "ground_truth = targs_test\n",
        "\n",
        "# ID de l'image\n",
        "ID = int(targs_test[0]['image_id'])\n",
        "print(\"ID : {}\".format(ID))\n",
        "# Path\n",
        "path = os.path.join(data_dir,\"test/\" + test_js['images'][ID]['file_name'])\n",
        "print(\"Path : {}\".format(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNFkiEQV50CC",
        "colab_type": "text"
      },
      "source": [
        "### Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qysrl_H-6kgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Post-processing ---\n",
        "\n",
        "# Non-Maximum Supression (NMS)\n",
        "nms_treshold = 0.35\n",
        "out_nms = [NMScustom(boxes=out[0]['boxes'], \n",
        "                     labels=out[0]['labels'], \n",
        "                     scores=out[0]['scores'], \n",
        "                     tresh=nms_treshold)]\n",
        "\n",
        "# Seuillage sur les scores\n",
        "cutoff_treshold = 0.20\n",
        "out_nms_cut = [CutOffScores(boxes=out_nms[0]['boxes'], \n",
        "                            labels=out_nms[0]['labels'], \n",
        "                            scores=out_nms[0]['scores'], \n",
        "                            tresh=cutoff_treshold)]\n",
        "\n",
        "# Print des résultats\n",
        "print('Résultats du post-processing')\n",
        "print('-'*50)\n",
        "print('{:<17}{:<7}{:<7}{:<7}{:<7}'.format(' ','GT','Preds','NMS','Cut-off'))\n",
        "print('-'*50)\n",
        "print('{:<17}{:<7}{:<7}{:<7}{:<7}'.format('Nbre de bbox :',len(ground_truth[0]['boxes']),len(out[0]['boxes']),len(out_nms[0]['boxes']),len(out_nms_cut[0]['boxes'])))\n",
        "print('-'*50)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0mjTgdW52uD",
        "colab_type": "text"
      },
      "source": [
        "### Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAeQSOKm8t8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Visualisation des prédictions ---\n",
        "\n",
        "%matplotlib inline\n",
        "#BatchPlot(imgs_test, targs_test, out_nms_cut)\n",
        "BatchPlot(imgs_test, targs_test, test_js, predictions=out_nms_cut, labels_dic=labels_dic ,save=False, img_names=True, legend=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZXbtRug57-t",
        "colab_type": "text"
      },
      "source": [
        "## Matrice de confusion du jeu de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URE9Vq_-XLHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Matrice de confusion globale ---\n",
        "''' Matrice de confusion de l'ensemble du jeu de test '''\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Dataloader ordonné \n",
        "order_dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                                    batch_size=1,\n",
        "                                                    shuffle=False,\n",
        "                                                    collate_fn=collate_fn,\n",
        "                                                    sampler=torch.utils.data.SequentialSampler(image_datasets[x]),\n",
        "                                                    num_workers=0)\n",
        "                      for x in ['train', 'val', 'test']}\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "model.eval()\n",
        "print_every = 1\n",
        "\n",
        "for i, (imgs_test, targs_test) in enumerate(order_dataloaders['test']):\n",
        "\n",
        "    # GPU\n",
        "    imgs_test = list(image.to(device) for image in imgs_test)\n",
        "    targs_test = [{k: v.to(device) for k, v in t.items()} for t in targs_test]\n",
        "\n",
        "    # Prédictions et ground-truth\n",
        "    out = model(imgs_test)\n",
        "    ground_truth = targs_test\n",
        "\n",
        "    # S'il n'y a aucune bbox prédite => FN\n",
        "    if len(out[0]['boxes'])==0:\n",
        "        for k in range(len(ground_truth[0]['labels'])):\n",
        "            res = np.array([int(ground_truth[0]['labels'][k]), int(0)])\n",
        "            res = res.reshape(1,2)\n",
        "            matches = np.concatenate((matches, res))\n",
        "        continue\n",
        "\n",
        "    # Non-Maximum Supression (NMS)\n",
        "    nms_treshold = 0.35\n",
        "    out_nms = [NMScustom(boxes=out[0]['boxes'], \n",
        "                        labels=out[0]['labels'], \n",
        "                        scores=out[0]['scores'], \n",
        "                        tresh=nms_treshold)]\n",
        "\n",
        "    # Seuillage sur les scores\n",
        "    cutoff_treshold = 0.20\n",
        "    out_nms_cut = [CutOffScores(boxes=out_nms[0]['boxes'], \n",
        "                                labels=out_nms[0]['labels'], \n",
        "                                scores=out_nms[0]['scores'], \n",
        "                                tresh=cutoff_treshold)]\n",
        "\n",
        "    # Matching des prédictions avec la ground-truth\n",
        "    tresh = 0.25\n",
        "    res = PredGTMatching(ground_truth, out_nms_cut, tresh)\n",
        "\n",
        "    # Variable contenant les matching pred-GT\n",
        "    if i == 0:\n",
        "        matches = res\n",
        "    else:\n",
        "        matches = np.concatenate((matches, res))\n",
        "\n",
        "    # ID de l'image\n",
        "    ID = int(targs_test[0]['image_id'])\n",
        "\n",
        "    if i % print_every == 0 or i == len(dataloaders['test'])-1:\n",
        "        print('='*50)\n",
        "        print('Image [{:<3}/{:<3}] traitée'.format(i+1, len(test_js['images'])))\n",
        "        print('Nom de l\\'image : {}'.format(test_js['images'][ID]['file_name']))\n",
        "        print(' ')\n",
        "        # Print des résultats\n",
        "        print('Résultats du post-processing')\n",
        "        print('-'*50)\n",
        "        print(' ')\n",
        "        print('{:<17}{:<7}{:<7}{:<7}{:<7}'.format(' ','GT','Preds','NMS','Cut-off'))\n",
        "        print('-'*50)\n",
        "        print('{:<17}{:<7}{:<7}{:<7}{:<7}'.format('Nbre de bbox :',len(ground_truth[0]['boxes']),len(out[0]['boxes']),len(out_nms[0]['boxes']),len(out_nms_cut[0]['boxes'])))\n",
        "        print('-'*50)\n",
        "        print(' ')\n",
        "        # Matrice de confusion\n",
        "        conf_matrix = confusion_matrix(res[:,0],res[:,1],labels=[0,1,2,3,4,5,6,7])\n",
        "        print('Matrice de confusion')\n",
        "        print('-'*50)\n",
        "        print(' ')\n",
        "        print(conf_matrix)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "636xxKqrYBtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construction de la matrice de confusion\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "truth = matches[:,0]\n",
        "predicted = matches[:,1]\n",
        "\n",
        "conf_matrix = confusion_matrix(truth,predicted,labels=[0,1,2,3,4,5,6,7])\n",
        "\n",
        "print('Matrice de confusion globale (test)')\n",
        "print('-'*65)\n",
        "print(' ')\n",
        "print(conf_matrix)\n",
        "print(' ')\n",
        "print('Métriques')\n",
        "print('-'*65)\n",
        "print(' ')\n",
        "print(classification_report(truth, predicted, target_names=class_names, digits=8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJdNDWTf1MEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Analyse d'erreur ---\n",
        "img_name = input('Nom de l\\'image : ')\n",
        "SpecificImgDisplay(img_name=img_name, dataset='test', dic=test_js, predictions=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}